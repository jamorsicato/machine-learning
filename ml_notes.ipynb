{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "limiting-bouquet",
   "metadata": {},
   "source": [
    "### ML Notes\n",
    "\n",
    "\n",
    "__What is Artificial Intelligence (AI):__ The computer science definition is the study of *intelligence agents*. Any device that takes in input to maximize its decisions. Intelligence displayed by machines. The name for an AI that mimicks human inteligence is *Strong AI* or *Artificial General Inteligence (AGI)*. Coloquiolly people say AI is anything where a computer trys to mimic cognitive function. Often AI is anything that hasnt been done yet, we use to think of it as any computer program that could beet a human at chess and that would be AI, but obviously thats not true. AI is a more catch all term for the study of trying to replicate human inteligence, while machine learning is the study of building alogrithms that teach themselves.\n",
    "\n",
    "__What is Machine Learning (ML):__ The study of using compouter algorithms that automatically get better with experience. ML is apart of AI, but not all AI is ML. ML models built a model based on a training set of data and test the model on a test set. All from data that is already gathered. A subset of ML that focuses on making predicitons with computers is closely realted to computational statistics. ML is also referred to as __Predictive Analytics__ in some fields.\n",
    "\n",
    "__What is Deep Learning:__ Deep learning is a subfield of ML that focuses on artificial neural networks. Deep learning may be a large missing piece in AGI when paired with faster quantum computer. Deep learning is essentially referring to a deep neural network.\n",
    "\n",
    "![AI Versus ML VDG](data/ai_vs_ml.png)\n",
    "\n",
    "### What Toolkits I need to be familiar with (I found these on Job Applications)\n",
    "- NumPy\n",
    "- SciPy\n",
    "- Scikit-learn\n",
    "- TensorFlow\n",
    "- Spark ML\n",
    "\n",
    "### What I need to know (Also foun these on Job Applications)\n",
    "\n",
    "- k-NN \n",
    "- Naive Bayes\n",
    "- SVM \n",
    "- Decision Forests\n",
    "- Gradient Boosted Decisions trees Ensembling\n",
    "- Neural Networks\n",
    "- clustering techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-viewer",
   "metadata": {},
   "source": [
    "# Types of Machine Learning\n",
    "## Learning Problems\n",
    "### Supervised Learning\n",
    "\n",
    "- Training data comprises examples of input vectors along with corresponding target values \n",
    "- Models are fit using training data and tested on a test data set \n",
    "- Can have 1 or more input variable\n",
    "- Input may be any type of data \n",
    "- we already know what our output should look like \n",
    "- predicting results in a discrete output\n",
    "\n",
    "__Classification:__ Supervised problems that work to predict a class label.(Classify the data set) An example of this would be trying to read handwritten digits. __Logistical Regression__ is an algorithm designed for classification problems.\n",
    "\n",
    "\n",
    "__Regression:__ Supervised problems that work to predict a numerical value. An example of this would be trying to predict the price of a house based on input of neighborhood values and output of the price of the house. __Linear Regression__ is an algorithm designed for supervised regression problems.\n",
    "\n",
    "__Linear Regression With One Variable__ (Univariant Linear Regression):\n",
    "\n",
    "- Taking an input $x_{input}$ and prediciting a continuous $y_{output}$\n",
    "- __hypothesis function__ $\\hat{y}=h_{\\theta}(x) = \\theta_0 + \\theta_1x$\n",
    "    -hypothesis function is how we are mapping out input x to out output y\n",
    "    \n",
    "- __Cost Function__ $J(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum_{i=1}^m (\\hat{y_i}-y_i)^2 = \\frac{1}{2m}\\sum_{i=1}^m (h_{\\theta}(x_i)-y_i)^2$\n",
    "    - AKA \"squared error\" or \"mean squared error\" function\n",
    "    - Best case $J(\\theta_0,\\theta_1)=0$ meaning our $h_{\\theta}(x)$ connects with all data points in $x_i$\n",
    "\n",
    "- __Gradient Descent__ $\\theta_j := \\theta_j-\\alpha\\frac{d}{d\\theta_j}J(\\theta_0,\\theta_1)$, repeat until convergence:\n",
    "    - $\\theta_j = \\theta_0 and \\theta_1$\n",
    "    - When we plug in the partial derivative of the cost function we end up with two terms, one with an extra x from the derivative\n",
    "\n",
    "__Linear Regression with Multiple Variables__\n",
    "\n",
    "- Add notation for options for multiple variabels\n",
    "    - x -> $x_j^{(i)}$ = the value of the feature j in the ith training example\n",
    "    - $x^{(i)}$ = the column vector for all feature inputs of $i^{th}$ training example \n",
    "    - m = number of training examples\n",
    "- __Multi-variable hypothesis function__ $\\hat{y}=h_{\\theta}(x) = \\theta_0 + \\theta_1x + \\theta_2x_2 ... \\theta_nx_n$\n",
    "    - $\\Theta_0$ = essentially the b in mx + b equation \n",
    "    - $\\theta_{1..n}$ = other features that are used to predict h\n",
    "    - $h_\\theta(x) = \\theta^Tx$ = vectorized form of our hypothesis\n",
    "    - X = training examples in row form\n",
    "    \n",
    "- __Cost Function__ \n",
    "    - $J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x_i)-y_i)^2$ = general version\n",
    "    - $J(\\theta) = \\frac{1}{2m}(X\\theta - y)^T(X\\theta - y)$ = vectorized version \n",
    "    - NOTE y = vectorized versions of y with all values\n",
    "\n",
    "- __Multi Variable Gradient Descent__\n",
    "    - $\\theta_j := \\theta_j-\\alpha\\frac{d}{d\\theta_j}J(\\theta_0,\\theta_1)$, but repeat for ALL values of x\n",
    "\n",
    "- __Feature Normalization (Feature scaling and mean normalization)__\n",
    "    - speeds up gradient descent by having wach of our features in the same range $0 <= x <= 1$\n",
    "    - subtract the mean $\\mu$ and divide by the range $s_i$\n",
    "    - $x_i := \\frac{x_i - \\mu}{s_i}, s_i = max - min $\n",
    "    \n",
    "- __Normal Equation__ ADD THE DERIVATION FOR FUN, LOTS OF LINEAR ALGREBRA [here](https://en.wikipedia.org/wiki/Linear_least_squares)\n",
    "    - useful when we dont have too many featurs, ie. when n is less than 10,000\n",
    "    - no need to use feature scaling with the normal equation \n",
    "    - $ 0(n^3)$\n",
    "    - $\\theta = (X^TX)^{-1}X^Ty$ \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Application__ great when we have a lot of data. Not inferior to other types of ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-family",
   "metadata": {},
   "source": [
    "### Unserpervised Learning\n",
    "\n",
    "- Involves using a model to describe or extract relationships in data\n",
    "- Operates purely on input data without targets\n",
    "\n",
    "\n",
    "__Clustering Unsupervised__ Finds groups in data. An example of this would be __K-means__ clustering to discover data. K-means clustering is very popular! Essentially it groups similar data points together and discover underlying points. An example of this would be a taxi company letting an agent decide variables for a good or bad traffic day without ever being gioven labaled data\n",
    "\n",
    "__Density Estimation__ Summarizes the distribution of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-vegetable",
   "metadata": {},
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "## Hybrid Learning Problems\n",
    "### Semi-supervised Learning \n",
    "### Self-supervised Learning\n",
    "### Multi-Instance Learning\n",
    "\n",
    "## Statistical Interference\n",
    "### Inductive Learning\n",
    "### Deductive Learning\n",
    "### Transductive Learning\n",
    "\n",
    "## Learning Techniques\n",
    "### Multi-Task Learning\n",
    "### Active Learning\n",
    "### Online Learning\n",
    "### Transfer Learning\n",
    "### Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-telescope",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network \n",
    "\n",
    "__Motivation__\n",
    "- can train them with youtube videos\n",
    "- can train them with reinforcement learning\n",
    "- can train them with high or low resolution imagery\n",
    "\n",
    "__Libraries__\n",
    "- Tensor Flow: good for large projects and is vertically integratable\n",
    "- PyTorch: Good for getting something up and running fast\n",
    "\n",
    "__Keras Sequential Model__\n",
    "- The easiest way to build a modiel in Keras\n",
    "- Allows the ability to build model layer by layer\n",
    "\n",
    "__Basic Overview__ \n",
    "\n",
    "- Construction Phase: Build Graph\n",
    "- Execution phase: \n",
    "- used for any 2d,3d,4d data. You could even use this on something like sound or text. \n",
    "- Unlike a fully connected neural network like MLP, the locality of data within the input vector (or matrix),is important (This is why I can use a CNN for a for my Bitcoin Trading A)\n",
    "\n",
    "__convolution__\n",
    "- compiles learning from matrix of images\n",
    "- images are compared using small little windows of the bigger image through filtering \n",
    "- filter adds up and averages values for each sliding window portion of greater image\n",
    "- the repeated use of a convolution filter creates what is known as a feature map\n",
    "- feature maps reveal more information about what is happening in an image\n",
    "- convolution is useful in computer vision becasue it revelas features in the input image \n",
    "\n",
    "__pooling (Subsampaling Layer)__\n",
    "- essentially shrinks convolved image by taking maximum value from small 3 by 3 windows\n",
    "- this shrinks our stack of images\n",
    "- CNN-TA is a package used for building filter,  sizes of the filter: (3X3),(4X4),(5X5), but a smaller filter will pick up much more detailed information.\n",
    "\n",
    "__Normalizaion__\n",
    "- changes all negative values to 0 \n",
    "\n",
    "\n",
    "After these three steps we actually stack all of the layers so the output of 1 turns into the inout of another. Note that each iteration through the pooling step will reduce size. \n",
    "\n",
    "We can make a deep stack if for a more refined model\n",
    "\n",
    "In a fully connected layer, the refined deep stack will be connected to different output. So we can then use the model to predict what a new input will be connect to. These are controlled by __voting weights__\n",
    "\n",
    "__Backpropogation__: \n",
    "\n",
    "__Gradient Descent (add negative parabola graph)__\n",
    "\n",
    "__Hyperparameters__ \n",
    "- convolution {number of features, size of features}\n",
    "- pooling {window size, window stride}\n",
    "- fully connected{number of neurons}\n",
    "- how many layers?\n",
    "- what order? \n",
    "\n",
    "LIMITATIONS\n",
    "- really only designed to capture local spatial patterns\n",
    "- if the data cant look like an image, you cant use CNN\n",
    "- CNN are great at finding patterns and using them to classify problems, but if you data can be rearanged its not useful.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "# make a ml dictionary and a study card program below\n",
    "\n",
    "ml_dict = {\n",
    "    \"Artificial Inteligence\": \"the study of intelligence agents. Any device that takes in input to maximize its decisions\",\n",
    "    \"Machine Learning\"      : \"The study of using compouter algorithms that automatically get better with experience\",\n",
    "    \"Deep Learning\"         : \"Deep learning is a subfield of ML that focuses on artificial neural networks\",\n",
    "    \"Classification\"        : \"A type of supervised machine learning that trys to classify data and label it\",\n",
    "    \"Regressiion\"           : \"A type of supervised machine learning that takes input variables and predicts a numerical value\",\n",
    "    \"K-means clustering\"    : \"An unsupervised algorithm that groups data into k numbers of clusters\",\n",
    "    \"Convolution\"           : \"A method of filtering that convolves a small X by X filter with the larger Y by Y image. The result essentially is an averaged image of initial input image\",\n",
    "    \"Pooling\"               : \"Part of Convolutional Nerual Networks. Pooling comes after the image is convolved and takes the maximum value in a N by N window to reduce the size of the image.\",\n",
    "    \"Normalization\"         : \"Need to add a beter definition for this: normalization creates a standard for all data in the window to be modeled after\",\n",
    "    \"CNN graph\"             : \"\",\n",
    "    \"Cost Function\"         : \"The function that sees how far off a linear regression projection is from the actual data points\",\n",
    "    \"Objective Fucntion\"    : \"Similar to the cost function, but slightly different somehow\",\n",
    "    \"Hypothesis\"            : \"A function based on a coefficient weighted representation of each feature used to predict our outcome, ceficients are often called theta\"\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-singer",
   "metadata": {},
   "source": [
    "__RESOURCES:__\n",
    "- [AI](https://en.wikipedia.org/wiki/Artificial_intelligence)\n",
    "- [Quantum Machine Intelligence](https://link.springer.com/article/10.1007/s42484-019-00006-5)\n",
    "- [What Estimator to Use](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "- [Machine Learning Info](https://machinelearningmastery.com/types-of-learning-in-machine-learning/)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
